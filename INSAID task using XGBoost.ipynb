{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dbd3d23",
   "metadata": {},
   "source": [
    "# Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d21aac39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace975b3",
   "metadata": {},
   "source": [
    "# Uploading data and selecting variables to use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f584d0",
   "metadata": {},
   "source": [
    "#\n",
    "I have uploaded Fraud.csv .By analysing the data I found that I have to predict 2nd last column on the basis of 1st 9 columns. Also I found that data in the 4th and 7th column are names only which does not affect our model of prediction so I decided to choose 1-9 columns except 4th and 7th as X and 10th column as y.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9082d13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Fraud.csv')\n",
    "X = dataset.iloc[:,[0,1,2,4,5,7,8]].values\n",
    "y = dataset.iloc[:, -2].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f257c289",
   "metadata": {},
   "source": [
    "# Data cleaning including missing values, outliers and multi-collinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed21f84",
   "metadata": {},
   "source": [
    "# \n",
    "Since data given is too large so we can't check every column but there may be missing values in the data so I have imported simple imputer from sklearn.impute and replaced missing data by mean of data in that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fdb235e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer.fit(X[:, 2:7])\n",
    "X[:, 2:7] = imputer.transform(X[:, 2:7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3616ab",
   "metadata": {},
   "source": [
    "I found that data in 2nd column was a categorical data so I decided to replace them by some binary code so I imported column transformer from sklearn.compose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66a721d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9b1657",
   "metadata": {},
   "source": [
    "I devided the given data in the ratio of 4:1 anad named 4/5 of it as X_train and y_train and the other part as X_test nad y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d18b0a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac157423",
   "metadata": {},
   "source": [
    "I found that datasets which will be used for training and testing were in different ranges so I decided to bring them in range of (-3,3).So I imported standardscalar from sklearn.preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3771f024",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train[:, 6:] = sc.fit_transform(X_train[:, 6:])\n",
    "X_test[:, 6:] = sc.transform(X_test[:, 6:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de2d509",
   "metadata": {},
   "source": [
    "# Choosing a model for prediction and describing it\n",
    "I have compared acccuracies of different classification models and found that XGBoost classifier has highest accuracy.\n",
    "# XGBoost\n",
    "XGBoost is an implementation of Gradient Boosted decision trees. XGBoost models majorly dominate in many Kaggle Competitions.\n",
    "\n",
    "In this algorithm, decision trees are created in sequential form. Weights play an important role in XGBoost. Weights are assigned to all the independent variables which are then fed into the decision tree which predicts results. The weight of variables predicted wrong by the tree is increased and these variables are then fed to the second decision tree. These individual classifiers/predictors then ensemble to give a strong and more precise model. It can work on regression, classification, ranking, and user-defined prediction problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c0de7e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "classifier = XGBClassifier()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b34ef24",
   "metadata": {},
   "source": [
    "# Demonstration of performance\n",
    "We have not used testing data in the training so now we will make prdiction for X_test and then compare y_pred with y_test to compute accuracy and hence we will find performance of the given model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70035b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1270840      37]\n",
      " [    205    1442]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9998098267694755"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "y_pred = classifier.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33100471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.98 %\n",
      "Standard Deviation: 0.00 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aacdec4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc0c4ab",
   "metadata": {},
   "source": [
    "# key factors that predict fraudulent customer\n",
    "Step,Type,Amount,Old balnce ,New balance thses are the features used in the given model which predicts fraudaulent customer. yes ,These factors make sense as thse features will show some abnormal behaviour when the customer is fraud."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e656f331",
   "metadata": {},
   "source": [
    "# What kind of prevention should be adopted while company update its infrastructure?\n",
    "Company should see features of all customers and use these type of testing models to predict whether the customer is fraudaulent or not.\n",
    "# Assuming these actions have been implemented, how would you determine if they work?\n",
    "We will again check the accuracy of our model to see whether it is working or not in the future if fraudaulent features changes then we may need to change model and try some different model for prediction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
