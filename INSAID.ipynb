{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dbd3d23",
   "metadata": {},
   "source": [
    "# Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d21aac39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace975b3",
   "metadata": {},
   "source": [
    "# Uploading data and selecting variables to use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f584d0",
   "metadata": {},
   "source": [
    "#\n",
    "I have uploaded Fraud.csv .By analysing the data I found that I have to predict 2nd last column on the basis of 1st 9 columns. Also I found that data in the 4th and 7th column are names only which does not affect our model of prediction so I decided to choose 1-9 columns except 4th and 7th as X and 10th column as y.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9082d13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Fraud.csv')\n",
    "X = dataset.iloc[:,[0,1,2,4,5,7,8]].values\n",
    "y = dataset.iloc[:, -2].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f257c289",
   "metadata": {},
   "source": [
    "# Data cleaning including missing values, outliers and multi-collinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed21f84",
   "metadata": {},
   "source": [
    "# \n",
    "Since data given is too large so we can't check every column but there may be missing values in the data so I have imported simple imputer from sklearn.impute and replaced missing data by mean of data in that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fdb235e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer.fit(X[:, 2:7])\n",
    "X[:, 2:7] = imputer.transform(X[:, 2:7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3616ab",
   "metadata": {},
   "source": [
    "I found that data in 2nd column was a categorical data so I decided to replace them by some binary code so I imported column transformer from sklearn.compose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66a721d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9b1657",
   "metadata": {},
   "source": [
    "I devided the given data in the ratio of 4:1 anad named 4/5 of it as X_train and y_train and the other part as X_test nad y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d18b0a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac157423",
   "metadata": {},
   "source": [
    "I found that datasets which will be used for training and testing were in different ranges so I decided to bring them in range of (-3,3).So I imported standardscalar from sklearn.preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3771f024",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train[:, 6:] = sc.fit_transform(X_train[:, 6:])\n",
    "X_test[:, 6:] = sc.transform(X_test[:, 6:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d82030",
   "metadata": {},
   "source": [
    "# Choosing a model for prediction and describing it\n",
    "I have compared acccuracies of different classification models and found that decision tree classifier has highest accuracy.\n",
    "# Decision tree Classifier\n",
    "Decision Tree is a Supervised learning technique that can be used for both classification and Regression problems, but mostly it is preferred for solving Classification problems. It is a tree-structured classifier, where internal nodes represent the features of a dataset, branches represent the decision rules and each leaf node represents the outcome.\n",
    "In a Decision tree, there are two nodes, which are the Decision Node and Leaf Node. Decision nodes are used to make any decision and have multiple branches, whereas Leaf nodes are the output of those decisions and do not contain any further branches.\n",
    "The decisions or the test are performed on the basis of features of the given dataset.\n",
    "It is a graphical representation for getting all the possible solutions to a problem/decision based on given conditions.\n",
    "It is called a decision tree because, similar to a tree, it starts with the root node, which expands on further branches and constructs a tree-like structure.\n",
    "In order to build a tree, we use the CART algorithm, which stands for Classification and Regression Tree algorithm.\n",
    "A decision tree simply asks a question, and based on the answer (Yes/No), it further split the tree into subtrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "118d30e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4669f18",
   "metadata": {},
   "source": [
    "# Demonstration of performance \n",
    "We have not used testing data in the training so now we will make prdiction for X_test and then compare y_pred with y_test to compute accuracy and hence we will find performance of the given model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88b32e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1270727     150]\n",
      " [    187    1460]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9997351719888976"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "y_pred = classifier.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebb8266",
   "metadata": {},
   "source": [
    "#  key factors that predict fraudulent customer\n",
    "Step,Type,Amount,Old balnce ,New balance thses are the features used in the given model which predicts fraudaulent customer. yes ,These factors make sense as thse features will show some abnormal behaviour when the customer is fraud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34dbed74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e656f331",
   "metadata": {},
   "source": [
    "# What kind of prevention should be adopted while company update its infrastructure?\n",
    "Company should see features of all customers and use these type of testing models to predict whether the customer is fraudaulent or not.\n",
    "# Assuming these actions have been implemented, how would you determine if they work?\n",
    "We will again check the accuracy of our model to see whether it is working or not in the future if fraudaulent features changes then we may need to change model and try some different model for prediction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
